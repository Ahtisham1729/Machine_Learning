{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NEU Steel Surface Defect Clustering\n",
        "**K-Means Clustering and PCA Analysis on Image Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports\n",
        "import os, shutil, random\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "plt.style.use('seaborn-v0_8-darkgrid')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Sampling Balanced Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sample_images(src_root, dst_root, n_samples, seed=None):\n",
        "    random.seed(seed)\n",
        "    os.makedirs(dst_root, exist_ok=True)\n",
        "    classes = sorted(os.listdir(src_root))\n",
        "    for cls in classes:\n",
        "        src_cls_dir = os.path.join(src_root, cls)\n",
        "        dst_cls_dir = os.path.join(dst_root, cls)\n",
        "        if not os.path.isdir(src_cls_dir):\n",
        "            continue\n",
        "        os.makedirs(dst_cls_dir, exist_ok=True)\n",
        "        images = [img for img in os.listdir(src_cls_dir) if img.lower().endswith(('.png','.jpg','.jpeg'))]\n",
        "        sampled = random.sample(images, min(n_samples, len(images)))\n",
        "        for img in sampled:\n",
        "            shutil.copy2(os.path.join(src_cls_dir, img), os.path.join(dst_cls_dir, img))\n",
        "        print(f\"{cls}: Sampled {len(sampled)} images\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Preprocess Images - Grayscale, Resize, Normalize, Flatten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_images(image_folder, num_images_per_class):\n",
        "    flattened_images = []\n",
        "    labels = []\n",
        "    class_labels = {\n",
        "        'crazing': 0,\n",
        "        'inclusion': 1,\n",
        "        'patches': 2,\n",
        "        'pitted_surface': 3,\n",
        "        'rolled-in_scale': 4,\n",
        "        'scratches': 5\n",
        "    }\n",
        "    for class_folder in os.listdir(image_folder):\n",
        "        class_path = os.path.join(image_folder, class_folder)\n",
        "        if os.path.isdir(class_path):\n",
        "            image_files = [f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "            sampled_images = random.sample(image_files, min(num_images_per_class, len(image_files)))\n",
        "            for image in sampled_images:\n",
        "                img_path = os.path.join(class_path, image)\n",
        "                img = cv2.imread(img_path)\n",
        "                if img is None: continue\n",
        "                img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "                img_resized = cv2.resize(img_gray, (64, 64))\n",
        "                img_norm = img_resized / 255.0\n",
        "                flattened_images.append(img_norm.reshape(-1))\n",
        "                labels.append(class_labels[class_folder])\n",
        "    return np.vstack(flattened_images), np.array(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: KMeans Clustering on Raw 4096-Dimensional Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fit KMeans on raw data\n",
        "kmeans = KMeans(n_clusters=6, init='k-means++', random_state=42)\n",
        "kmeans.fit(X_train)\n",
        "y_hat = kmeans.labels_\n",
        "\n",
        "# Cluster to class mapping\n",
        "cluster_to_label = {}\n",
        "for c in range(6):\n",
        "    members = y_train[y_hat == c]\n",
        "    if len(members) == 0:\n",
        "        cluster_to_label[c] = -1\n",
        "    else:\n",
        "        cluster_to_label[c] = Counter(members).most_common(1)[0][0]\n",
        "y_train_mapped = np.vectorize(cluster_to_label.get)(y_hat)\n",
        "print(\"Train Accuracy:\", accuracy_score(y_train, y_train_mapped))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: PCA + KMeans (Dimensionality Tuning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler = StandardScaler(with_std=False)\n",
        "X_train_centered = scaler.fit_transform(X_train)\n",
        "X_test_centered = scaler.transform(X_test)\n",
        "\n",
        "component_list = [5, 10, 20, 30, 40, 50, 64]\n",
        "results = []\n",
        "test_results = []\n",
        "\n",
        "for l in component_list:\n",
        "    pca = PCA(n_components=l)\n",
        "    X_train_l = pca.fit_transform(X_train_centered)\n",
        "    kmeans_l = KMeans(n_clusters=6, init='k-means++', random_state=42)\n",
        "    y_hat_l = kmeans_l.fit_predict(X_train_l)\n",
        "\n",
        "    mapping_l = {}\n",
        "    for c in range(6):\n",
        "        members = y_train[y_hat_l == c]\n",
        "        mapping_l[c] = Counter(members).most_common(1)[0][0] if len(members) > 0 else -1\n",
        "\n",
        "    y_mapped_l = np.vectorize(mapping_l.get)(y_hat_l)\n",
        "    acc_train = accuracy_score(y_train, y_mapped_l)\n",
        "    results.append((l, acc_train))\n",
        "\n",
        "    X_test_l = pca.transform(X_test_centered)\n",
        "    y_hat_test_l_raw = kmeans_l.predict(X_test_l)\n",
        "    y_hat_test_l = np.vectorize(mapping_l.get)(y_hat_test_l_raw)\n",
        "    acc_test = accuracy_score(y_test, y_hat_test_l)\n",
        "    test_results.append((l, acc_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Plot Test Error vs Number of PCA Components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "l_vals, test_accs = zip(*test_results)\n",
        "test_errors = [1.0 - acc for acc in test_accs]\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(l_vals, test_errors, marker='o')\n",
        "plt.xlabel('Number of PCA Components')\n",
        "plt.ylabel('Test Classification Error')\n",
        "plt.title('PCA Dimensionality vs Test Error')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: 3D PCA Visualization of Clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pca_3d = PCA(n_components=3)\n",
        "X_3d = pca_3d.fit_transform(X_train_centered)\n",
        "fig = plt.figure(figsize=(10,6))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.scatter(X_3d[:, 0], X_3d[:, 1], X_3d[:, 2], c=y_hat, cmap='rainbow', s=20)\n",
        "ax.set_title('3D PCA Scatter Plot Colored by Cluster')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Conclusion\n",
        "- KMeans on raw 4096-D images performs poorly due to high dimensionality.\n",
        "- PCA improves clustering performance and computational efficiency.\n",
        "- The optimal number of PCA components is around 40.\n",
        "- Final model achieves best generalization with PCA + KMeans."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
